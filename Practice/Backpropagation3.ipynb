{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series,DataFrame\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input Data\n",
    "i1, i2 = 0.05, 0.10\n",
    "#Output Data\n",
    "target1, target2 = 0.01, 0.99\n",
    "\n",
    "#Weights\n",
    "w1, w2, w3, w4, w5, w6, w7, w8 = 0.15, 0.20, 0.25,0.30, 0.40, 0.45, 0.50, 0.55\n",
    "b1, b2, b3, b4 = 0.35, 0.35, 0.60, 0.60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backpropagation(i1, i2, target1, target2, w1, w2, w3, w4, w5, w6, w7, w8, b1, b2, b3, b4):\n",
    "    \n",
    "    def sigmoid(a):\n",
    "        s = 1 / (1 + math.e**-a)\n",
    "        return s\n",
    "\n",
    "    def hidden1(i1, w1, i2, w2, b1):\n",
    "        return i1*w1 + i2*w2 + b1\n",
    "    \n",
    "    def totalError(target1, outO1, target2, outO2):\n",
    "        Eo1 = 0.5 * (target1 - outO1)**2\n",
    "        Eo2 = 0.5 * (target2 - outO2)**2\n",
    "        Etotal = Eo1 + Eo2\n",
    "        return Etotal\n",
    "        \n",
    "    outH1 = sigmoid(hidden1(i1, w1, i2, w3, b1))\n",
    "    outH2 = sigmoid(hidden1(i1, w2, i2, w4, b2))\n",
    "    outO1 = sigmoid(hidden1(outH1, w5, outH2, w7, b3))\n",
    "    outO2 = sigmoid(hidden1(outH1, w6, outH2, w8, b4))\n",
    "    Etotal = totalError(target1, outO1, target2, outO2)\n",
    "    print(Etotal)\n",
    "    return outH1, outH2, outO1, outO2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#args {i, target2, outO2, w1, w2}\n",
    "def updateWeightsV1(target, outH, outO, w, *args):\n",
    "\n",
    "    def Etotal_op(target, outO):\n",
    "        Etotal_op = (target - outO) * -1\n",
    "        return Etotal_op\n",
    "\n",
    "    def op_net(outO):\n",
    "        op_net1 = outO * (1 - outO)\n",
    "        return op_net1\n",
    "\n",
    "    def net_w(outH):\n",
    "        net_w1 = outH\n",
    "        return net_w1\n",
    "    \n",
    "    #新しいウェイト\n",
    "    def learingRatio(w,new_w):\n",
    "        a = 0.5\n",
    "        w = w - new_w * a\n",
    "        return w\n",
    "    \n",
    "    bool = args[0]\n",
    "    if(bool):\n",
    "        new_w = net_w(outH) * op_net(outO) * Etotal_op(target, outO)\n",
    "    else:\n",
    "        i, target2, outO2, w1, w2 = args[1], args[2], args[3], args[4], args[5]\n",
    "        \n",
    "        new_w = net_w(i) * op_net(outH) * (net_w(w1) * op_net(outO) * Etotal_op(target, outO) + net_w(w2) * op_net(outO2) * Etotal_op(target2, outO2))\n",
    "        \n",
    "    w = learingRatio(w,new_w)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.303658313630144\n",
      "0.2858773900703121\n",
      "0.2673887367559863\n",
      "0.24842932933749917\n",
      "0.22930337174642984\n",
      "0.21035883940875874\n",
      "0.19195286250920346\n",
      "0.1744128669575321\n",
      "0.15800276178328812\n",
      "0.14290202993974252\n",
      "0.12920093854750164\n",
      "0.11690979117167119\n",
      "0.10597677705550386\n",
      "0.09630845051421094\n",
      "0.08778840509590594\n",
      "0.08029188289938166\n",
      "0.07369585002777122\n",
      "0.06788511308299518\n",
      "0.0627554448849288\n",
      "0.058214681756068413\n",
      "0.0541825729801005\n",
      "0.05058994409337528\n",
      "0.04737754443103264\n",
      "0.04449480538014856\n",
      "0.04189863691648356\n",
      "0.039552326535887194\n",
      "0.037424566283134314\n",
      "0.03548861173673827\n",
      "0.03372156536212863\n",
      "0.03210377143478132\n",
      "0.030618308086620083\n",
      "0.029250562293446553\n",
      "0.027987874815825722\n",
      "0.02681924366771408\n",
      "0.025735076308902316\n",
      "0.0247269822833689\n",
      "0.023787599387337186\n",
      "0.02291044762774069\n",
      "0.022089806228558932\n",
      "0.02132060977551577\n",
      "0.020598360279762962\n",
      "0.019919052509680218\n",
      "0.01927911040660811\n",
      "0.01867533278268292\n",
      "0.018104846811957048\n",
      "0.017565068082253475\n",
      "0.017053666185156382\n",
      "0.016568534993757208\n",
      "0.01610776691925973\n",
      "0.015669630553998174\n",
      "0.015252551204465569\n",
      "0.014855093897336505\n",
      "0.014475948507240611\n",
      "0.014113916709667145\n",
      "0.013767900507856057\n",
      "0.013436892120486769\n",
      "0.013119965048731946\n",
      "0.01281626616788167\n",
      "0.012525008711143426\n",
      "0.012245466032105388\n",
      "0.011976966048308953\n",
      "0.01171888628189256\n",
      "0.01147064942474912\n",
      "0.011231719365408004\n",
      "0.011001597623188761\n",
      "0.01077982014230058\n",
      "0.010565954404669727\n",
      "0.010359596825523343\n",
      "0.010160370400273191\n",
      "0.009967922575138746\n",
      "0.009781923317314001\n",
      "0.009602063363399346\n",
      "0.009428052627349434\n",
      "0.009259618751387684\n",
      "0.009096505785255133\n",
      "0.008938472980833292\n",
      "0.008785293690643368\n",
      "0.008636754360004948\n",
      "0.008492653603761112\n",
      "0.00835280135946469\n",
      "0.008217018109789757\n",
      "0.008085134167699386\n",
      "0.007956989018577918\n",
      "0.007832430714134664\n",
      "0.007711315313417017\n",
      "0.007593506366741505\n",
      "0.007478874438769715\n",
      "0.007367296667328228\n",
      "0.007258656354903387\n",
      "0.007152842590037491\n",
      "0.007049749896117611\n",
      "0.006949277905284355\n",
      "0.006851331055400363\n",
      "0.006755818308207413\n",
      "0.006662652886972599\n",
      "0.006571752032076763\n",
      "0.006483036773136611\n",
      "0.006396431716376315\n",
      "0.006311864846077009\n",
      "0.00622926733903312\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    outH1, outH2, outO1, outO2 = backpropagation(i1, i2, target1, target2,w1, w2, w3, w4, w5, w6, w7, w8, b1, b2, b3, b4)\n",
    "\n",
    "    new_w5 = updateWeightsV1(target1, outH1, outO1, w5, True)\n",
    "    new_w6 = updateWeightsV1(target2, outH1, outO2, w6, True)\n",
    "    new_w7 = updateWeightsV1(target1, outH2, outO1, w7, True)\n",
    "    new_w8 = updateWeightsV1(target2, outH2, outO2, w8, True)\n",
    "\n",
    "    new_w1 = updateWeightsV1(target1, outH1, outO1, w1, False, i1, target2, outO2, w5, w6)\n",
    "    new_w2 = updateWeightsV1(target1, outH2, outO1, w2, False, i1, target2, outO2, w7, w8)\n",
    "    new_w3 = updateWeightsV1(target1, outH1, outO1, w3, False, i2, target2, outO2, w5, w6)\n",
    "    new_w4 = updateWeightsV1(target1, outH2, outO1, w4, False, i2, target2, outO2, w7, w8)\n",
    "\n",
    "    new_b3 = updateWeightsV1(target1, 1, outO1, b3, True)\n",
    "    new_b4 = updateWeightsV1(target2, 1, outO2, b4, True)\n",
    "    new_b1 = updateWeightsV1(target1, outH1, outO1, b1, False, 1, target2, outO2, w5, w6)\n",
    "    new_b2 = updateWeightsV1(target1, outH2, outO1, b2, False, 1, target2, outO2, w7, w8)\n",
    "    \n",
    "    w1, w2, w3, w4, w5, w6, w7, w8, b1, b2, b3, b4 = new_w1, new_w2, new_w3, new_w4, new_w5, new_w6, new_w7, new_w8, new_b1, new_b2, new_b3, new_b4\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
